import logging
import sys
import queue
import base64
import json
import torch
import torch.nn as nn
import torchvision
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from io import BytesIO
from PIL import Image

server_url = "http://localhost:55989/ChatHub" #replace with your signalR service

  
    
transform = torchvision.transforms.Compose([
                           transforms.Resize(32),
                           torchvision.transforms.ToTensor()
                           ])

    #### TRYING TO SEND A MESSAGE
def readb64(base64_string):
    sbuf = BytesIO()
    sbuf.write(base64.b64decode(base64_string))
    pimg = Image.open(sbuf)
    return pimg

def image_loader(image):
    image = transform(image).float()
    image = image.unsqueeze(0) 
    return image

 
# SIGNAL-R SERVICE
from signalrcore.hub_connection_builder import HubConnectionBuilder

work = queue.Queue()
 
def input_with_default(input_text, default_value):
    value = input(input_text.format(default_value))
    return default_value if value is None or value.strip() == "" else value



username =   "xilinx server"
handler = logging.StreamHandler()
handler.setLevel(logging.DEBUG)
hub_connection = HubConnectionBuilder()\
    .with_url(server_url, options={"verify_ssl": False}) \
    .configure_logging(logging.DEBUG, socket_trace=True, handler=handler) \
    .with_automatic_reconnect({
            "type": "interval",
            "keep_alive_interval": 10,
            "intervals": [1, 3, 5, 6, 7, 87, 3]
        }).build()

def classify(callbackUser):
    work.put( callbackUser  )

def registerServer():
     hub_connection.send(  "RegisterClassifier", [ "Azure u250"] )

      

hub_connection.on_open(registerServer)
hub_connection.on_close(lambda: print("connection closed"))

hub_connection.on("Classify", classify)
hub_connection.start()
message = None
 
#TODO
g = xir.Graph.deserialize("CNN_u250.xmodel")
subgraphs = get_child_subgraph_dpu(g)

dpu = vart.Runner.create_runner(subgraphs[0], "run"))

# input scaling
input_fixpos = all_dpu_runners[0].get_input_tensors()[0].get_attr("fix_point")
input_scale = 2**input_fixpos

'''get tensor'''
inputTensors = dpu.get_input_tensors()
outputTensors = dpu.get_output_tensors()
input_ndim = tuple(inputTensors[0].dims)
output_ndim = tuple(outputTensors[0].dims)

label_count = 10
# Do login

while True:
    todo = work.get(True,None) #wait forever until some image arrives to classify
 
    img = readb64(todo[1])

    #create loader from image
    eval_loader = image_loader(img)
 
    #TODO Covert image into 
    inputData = []
    inputData = [np.empty(input_ndim, dtype=np.int8, order="C")]

    #TODO: Cast image into 
    dpu.execute( inputData, outputData[len(ids)])
 
    predictions = outputData.data.numpy() #convert to Numpy array
 
    b=["%.2f" % i for i in predictions]
       
    #send all probabilities
    response = str(b)

    #invoke classifier
    hub_connection.send("ResponseClassification", [todo[0] , response ] )


hub_connection.stop()

sys.exit(0)